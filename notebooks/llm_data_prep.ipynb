{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d322d337",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49d7c9b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory: /home/hsozer/Projects/DeepLearning/recipe_bot\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "if os.getcwd().endswith('notebooks'):\n",
    "    # Move up one level to the project root\n",
    "    os.chdir('..') \n",
    "\n",
    "print(f\"Current Working Directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e85e6cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kaggle count: 225342\n",
      "Scraped count: 2867\n",
      "Final Training Set Size: 226816\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load both pickled datasets\n",
    "df_kaggle = pd.read_pickle('data/processed/clean_recipes.pkl')\n",
    "df_scraped = pd.read_pickle('data/processed/full_scraped_recipes.pkl')\n",
    "\n",
    "print(f\"Kaggle count: {len(df_kaggle)}\")\n",
    "print(f\"Scraped count: {len(df_scraped)}\")\n",
    "\n",
    "# Merge them\n",
    "df_combined = pd.concat([df_kaggle, df_scraped], ignore_index=True)\n",
    "\n",
    "# Remove if there's duplicates\n",
    "df_final = df_combined.drop_duplicates(subset=['name'], keep='last')\n",
    "\n",
    "# 4. Shuffling the final dataframe\n",
    "df_final = df_final.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "print(f\"Final Training Set Size: {len(df_final)}\")\n",
    "df = df_final\n",
    "\n",
    "# Save the final dataframe\n",
    "df.to_pickle('data/processed/final_recipes.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21fe68b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "from scripts.data_prep import generate_llm_dataset\n",
    "\n",
    "# CONFIG\n",
    "\n",
    "# Paths\n",
    "INPUT_PATH = \"data/processed/full_scraped_recipes.pkl\"\n",
    "OUTPUT_PATH = \"data/training/llm_train.jsonl\"\n",
    "\n",
    "# Thresholds\n",
    "MAX_LENGTH = 2048  # Max token length for the LLM\n",
    "\n",
    "# Meal keywords\n",
    "MEAL_KEYWORDS = {\n",
    "    'main-dish': 'Dinner',           # Rank 10\n",
    "    'side-dishes': 'Side Dish',      # Rank 42\n",
    "    'desserts': 'Dessert',           # Rank 23\n",
    "    'lunch': 'Lunch',                # Rank 48\n",
    "    'appetizers': 'Appetizer',       # Rank 55\n",
    "    'breakfast': 'Breakfast',        # Rank 65\n",
    "    'brunch': 'Brunch',              # Rank 56\n",
    "    'soups-stews': 'Soup',           # Rank 75\n",
    "    'salads': 'Salad',               # Rank 63\n",
    "    'beverages': 'Beverage',         # Rank 76\n",
    "    'cocktails': 'Beverage',         # Rank 137\n",
    "    'breads': 'Bread',               # Rank 64\n",
    "    'snacks': 'Snack',               # Rank 100\n",
    "    'finger-food': 'Snack'           # Rank 108\n",
    "}\n",
    "\n",
    "# Dietary keywords\n",
    "DIET_KEYWORDS = {\n",
    "    'low-sodium': 'Low-Sodium',          # Rank 22\n",
    "    'low-carb': 'Low-Carb',              # Rank 24\n",
    "    'healthy': 'Healthy',                # Rank 25\n",
    "    'healthy-2': 'Healthy',              # Rank 43\n",
    "    'low-cholesterol': 'Low-Cholesterol',# Rank 27\n",
    "    'low-calorie': 'Low-Calorie',        # Rank 28\n",
    "    'vegetarian': 'Vegetarian',          # Rank 29\n",
    "    'vegan': 'Vegan',                    # Rank 82\n",
    "    'low-protein': 'Low-Protein',        # Rank 34\n",
    "    'low-saturated-fat': 'Low-Fat',      # Rank 35\n",
    "    'low-fat': 'Low-Fat',                # Rank 50\n",
    "    'very-low-carbs': 'Keto',            # Rank 86\n",
    "    'high-protein': 'High-Protein',      # Rank 99\n",
    "    'diabetic': 'Diabetic-Friendly',     # Rank 107\n",
    "    'gluten-free': 'Gluten-Free',        # Rank 115\n",
    "    'egg-free': 'Egg-Free',              # Rank 123\n",
    "    'kosher': 'Kosher'                   # Rank 135\n",
    "}\n",
    "\n",
    "# Cooking method keywords\n",
    "METHOD_KEYWORDS = {\n",
    "    'oven': 'Oven Baked',                # Rank 37\n",
    "    'stove-top': 'Stove Top',            # Rank 51\n",
    "    'crock-pot-slow-cooker': 'Slow Cooker', # Rank 106\n",
    "    'no-cook': 'No-Cook',                # Rank 110\n",
    "    'grilling': 'Grilled',               # Rank 128\n",
    "    'barbecue': 'BBQ',                   # Rank 140\n",
    "    'food-processor-blender': 'Blended'  # Rank 126\n",
    "}\n",
    "\n",
    "STYLE_KEYWORDS = {\n",
    "    'easy': 'Easy',                      # Rank 6\n",
    "    'beginner-cook': 'Beginner Friendly',# Rank 30\n",
    "    'inexpensive': 'Budget Friendly',    # Rank 33\n",
    "    'kid-friendly': 'Kid Friendly',      # Rank 41\n",
    "    'toddler-friendly': 'Kid Friendly',  # Rank 134\n",
    "    'comfort-food': 'Comfort Food',      # Rank 44\n",
    "    'for-1-or-2': 'Single Serving',      # Rank 49\n",
    "    'for-large-groups': 'Crowd Pleaser', # Rank 58\n",
    "    'weeknight': 'Weeknight',            # Rank 53\n",
    "    'one-dish-meal': 'One-Pot',          # Rank 60\n",
    "    'potluck': 'Potluck',                # Rank 77\n",
    "    'spicy': 'Spicy',                    # Rank 89\n",
    "    'romantic': 'Date Night',            # Rank 122\n",
    "    'oamc-freezer-make-ahead': 'Meal Prep' # Rank 139\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46a82fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è≥ Generating training pairs...\n",
      "   - Processed 223498 items.\n",
      "   - Skipped 3318 items due to length > 2048.\n",
      "‚è≥ Saving to data/training/llm_train.jsonl...\n",
      "‚úÖ Done! Ready for QLoRA.\n",
      "\n",
      "--- Sample Entry ---\n",
      "INSTRUCTION: You are a smart chef. Generate a recipe that uses the provided ingredients and strictly follows the context constraints.\n",
      "INPUT:       Ingredients: turkey, campbell's cream of chicken soup, milk, mixed vegetables, cornstarch, water. Context: Dinner, Easy, Beginner Friendly\n",
      "OUTPUT:      **Easy As Can Be Creamed Turkey   Veggies**\n",
      "\n",
      "Ingredients:\n",
      "- turkey\n",
      "- campbell's cream of chicken soup\n",
      "- milk\n",
      "- mixed vegetables\n",
      "- cornstarch\n",
      "- water\n",
      "\n",
      "**Instructions:**\n",
      "1. In a medium sized bowl add soup and milk , mixing well\n",
      "2. Pour soup mixture into a large skillet\n",
      "3. Add turkey and veggies\n",
      "4. Bring to a simmer over medium heat\n",
      "5. If it looks to thin , add cornstarch mixed with water\n",
      "6. Stir until thickened\n",
      "7. Season with pepper to taste\n",
      " </s>\n"
     ]
    }
   ],
   "source": [
    "# Run the Processing Script\n",
    "print(\"‚è≥ Generating training pairs...\")\n",
    "training_data = generate_llm_dataset(\n",
    "    df, \n",
    "    meal_map=MEAL_KEYWORDS, \n",
    "    diet_map=DIET_KEYWORDS, \n",
    "    method_map=METHOD_KEYWORDS,\n",
    "    style_map=STYLE_KEYWORDS,\n",
    "    max_length=MAX_LENGTH\n",
    ")\n",
    "\n",
    "# Save to JSONL\n",
    "print(f\"‚è≥ Saving to {OUTPUT_PATH}...\")\n",
    "os.makedirs(os.path.dirname(OUTPUT_PATH), exist_ok=True)\n",
    "\n",
    "with open(OUTPUT_PATH, 'w', encoding='utf-8') as f:\n",
    "    for entry in training_data:\n",
    "        json.dump(entry, f)\n",
    "        f.write('\\n')\n",
    "\n",
    "print(f\"‚úÖ Done! Ready for QLoRA.\")\n",
    "\n",
    "# 4. Preview\n",
    "print(\"\\n--- Sample Entry ---\")\n",
    "print(f\"INSTRUCTION: {training_data[0]['instruction']}\")\n",
    "print(f\"INPUT:       {training_data[0]['input']}\")\n",
    "print(f\"OUTPUT:      {training_data[0]['output']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee433c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import random\n",
    "import glob\n",
    "import os\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# PATHS\n",
    "# Original robotic dataset\n",
    "EXISTING_RECIPES_PATH = \"data/training/llm_train.jsonl\"\n",
    "# Chat dataset\n",
    "NEW_CHEF_DATA_FOLDER = \"data/synthetic/chef_dataset.jsonl\"\n",
    "\n",
    "# The final file for Fine-Tuning\n",
    "TRAIN_OUTPUT_PATH = \"data/training/hybrid_train.jsonl\"\n",
    "\n",
    "# CONFIG \n",
    "RECIPE_FT_COUNT = 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9d852a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading original recipe dataset...\n",
      "‚úÖ Loaded 223498 total recipes.\n",
      "üìä Split Statistics:\n",
      "   - Fine-Tuning Recipes: 20000\n",
      "   - RAG Knowledge Base:  223498\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading original recipe dataset...\")\n",
    "\n",
    "data = []\n",
    "with open(EXISTING_RECIPES_PATH, 'r') as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        if not line: continue\n",
    "        try:\n",
    "            data.append(json.loads(line))\n",
    "        except json.JSONDecodeError:\n",
    "            continue\n",
    "\n",
    "# Convert to DataFrame\n",
    "full_df = pd.DataFrame(data)\n",
    "print(f\"‚úÖ Loaded {len(full_df)} total recipes.\")\n",
    "\n",
    "# Shuffle once before splitting\n",
    "full_df = shuffle(full_df, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Top 20k for Fine-Tuning\n",
    "train_recipes_df = full_df.head(RECIPE_FT_COUNT).copy()\n",
    "\n",
    "print(f\"üìä Split Statistics:\")\n",
    "print(f\"   - Fine-Tuning Recipes: {len(train_recipes_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164dea72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEMPLATE EXPANSION\n",
    "\n",
    "# INGREDIENT ONLY (Casual, Formal, Short, Long)\n",
    "INGREDIENT_PROMPTS = [\n",
    "    # Casual / Short\n",
    "    \"What can I cook with {ingredients}?\",\n",
    "    \"I have {ingredients}. Ideas?\",\n",
    "    \"Got {ingredients}. What now?\",\n",
    "    \"Make me something with {ingredients}.\",\n",
    "    \"Recipe for {ingredients}?\",\n",
    "    \"How do I use {ingredients}?\",\n",
    "    \"Dinner ideas using {ingredients}.\",\n",
    "    \"Lunch options with {ingredients}.\",\n",
    "    \"I found {ingredients} in the pantry.\",\n",
    "    \"Whip up a meal with {ingredients}.\",\n",
    "    \"Can {ingredients} be a meal?\",\n",
    "    \"Cooking with {ingredients}.\",\n",
    "    \"Just bought {ingredients}. Recipes?\",\n",
    "    \"Leftover {ingredients}. Help.\",\n",
    "    \"Any dishes strictly with {ingredients}?\",\n",
    "    \n",
    "    # Conversational\n",
    "    \"I'm staring at {ingredients} and have no clue what to make.\",\n",
    "    \"My partner bought {ingredients} and I need a plan.\",\n",
    "    \"I'd like to prepare a dish that highlights {ingredients}.\",\n",
    "    \"Could you suggest a menu that features {ingredients}?\",\n",
    "    \"I am looking for a reliable recipe involving {ingredients}.\",\n",
    "    \"Please help me combine {ingredients} into a tasty dish.\",\n",
    "    \"What pairs well with {ingredients} for a main course?\",\n",
    "    \"I want to try something new with {ingredients}.\",\n",
    "    \"Give me your best recommendation for {ingredients}.\",\n",
    "    \"How would a chef prepare {ingredients}?\",\n",
    "    \n",
    "    # Creative / Challenge\n",
    "    \"Challenge: I only have {ingredients}.\",\n",
    "    \"Iron Chef style: The secret ingredient is {ingredients}.\",\n",
    "    \"Can you turn {ingredients} into a gourmet meal?\",\n",
    "    \"Surprise me with a recipe for {ingredients}.\",\n",
    "    \"I'm bored of my usuals. What can I do with {ingredients}?\",\n",
    "    \"Invent a dish using {ingredients}.\",\n",
    "    \"If you had {ingredients}, what would you cook?\",\n",
    "    \"Transform these simple ingredients: {ingredients}.\",\n",
    "    \"I need a comfort meal using {ingredients}.\",\n",
    "    \"Make {ingredients} the star of the show.\"\n",
    "]\n",
    "\n",
    "# CONTEXT BASED (Dietary, Time, Method, Vibe)\n",
    "CONTEXT_PROMPTS = [\n",
    "    # Direct phrasing\n",
    "    \"I'm looking for a {context} recipe using {ingredients}.\",\n",
    "    \"Can you make a {context} dish with {ingredients}?\",\n",
    "    \"I have {ingredients}. Make something {context}.\",\n",
    "    \"Give me a {context} meal featuring {ingredients}.\",\n",
    "    \"How can I make a {context} dish using {ingredients}?\",\n",
    "    \n",
    "    # \"Need\" phrasing\n",
    "    \"I need a {context} dinner idea with {ingredients}.\",\n",
    "    \"I need something {context} made from {ingredients}.\",\n",
    "    \"We need a {context} option for {ingredients}.\",\n",
    "    \"My diet is {context}, and I have {ingredients}.\",\n",
    "    \"Keep it {context} please. Ingredients: {ingredients}.\",\n",
    "    \n",
    "    # \"Want\" phrasing\n",
    "    \"I want to eat {context}. I have {ingredients}.\",\n",
    "    \"I'm craving something {context} with {ingredients}.\",\n",
    "    \"I'm in the mood for {context} food using {ingredients}.\",\n",
    "    \"Can you satisfy a {context} craving with {ingredients}?\",\n",
    "    \"I'd love a {context} version of {ingredients}.\",\n",
    "    \n",
    "    # Question phrasing\n",
    "    \"Show me a {context} way to cook {ingredients}.\",\n",
    "    \"Do you have a {context} recipe for {ingredients}?\",\n",
    "    \"Is there a {context} way to prepare {ingredients}?\",\n",
    "    \"What is a good {context} dish with {ingredients}?\",\n",
    "    \"Find me a {context} dish with {ingredients}.\",\n",
    "    \n",
    "    # Complex / Specific\n",
    "    \"Please provide a {context} recipe that includes {ingredients}.\",\n",
    "    \"Make it {context} and use {ingredients}.\",\n",
    "    \"I am hosting a {context} dinner and have {ingredients}.\",\n",
    "    \"I need to use up my {ingredients} but keep it {context}.\",\n",
    "    \"Can you adapt {ingredients} into a {context} meal?\",\n",
    "    \"It's a {context} kind of night. I have {ingredients}.\",\n",
    "    \"Help me stay {context} with these ingredients: {ingredients}.\",\n",
    "    \"Any {context} chef tips for {ingredients}?\",\n",
    "    \"How to cook {ingredients} in a {context} style?\"\n",
    "]\n",
    "\n",
    "# CHEF INTROS (Personality Injection)\n",
    "CHEF_INTROS = [\n",
    "    # Enthusiastic\n",
    "    \"Here is a delicious recipe for you:\\n\\n\",\n",
    "    \"I'd love to help! Try this dish:\\n\\n\",\n",
    "    \"Let's get cooking! Here is a great choice:\\n\\n\",\n",
    "    \"Ooh, great ingredients! Try this:\\n\\n\",\n",
    "    \"I have the perfect idea for that:\\n\\n\",\n",
    "    \n",
    "    # Professional\n",
    "    \"Certainly! This fits your needs perfectly:\\n\\n\",\n",
    "    \"Here is a recipe that works well with those items:\\n\\n\",\n",
    "    \"This is a fantastic option:\\n\\n\",\n",
    "    \"Here is a classic preparation:\\n\\n\",\n",
    "    \"Allow me to suggest this recipe:\\n\\n\",\n",
    "    \n",
    "    # Confident\n",
    "    \"You can't go wrong with this:\\n\\n\",\n",
    "    \"Trust me, this is delicious:\\n\\n\",\n",
    "    \"This dish highlights your ingredients perfectly:\\n\\n\",\n",
    "    \"Here is a chef-approved recipe:\\n\\n\",\n",
    "    \"Simple, tasty, and perfect for you:\\n\\n\",\n",
    "    \n",
    "    # Helpful / Short\n",
    "    \"How about this?\\n\\n\",\n",
    "    \"Try this out:\\n\\n\",\n",
    "    \"Here you go:\\n\\n\",\n",
    "    \"One of my favorites:\\n\\n\",\n",
    "    \"Here is a wonderful way to use those ingredients:\\n\\n\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f12789b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Harmonizing recipe formats (This may take a moment)...\n",
      "‚úÖ Recipes Harmonized to Chef Persona\n"
     ]
    }
   ],
   "source": [
    "def harmonize_row(row):\n",
    "    raw_input = row.get('input', '')\n",
    "    raw_output = row.get('output', '')\n",
    "    \n",
    "    # Parse Input (Extract Ingredients & Context)\n",
    "    ingredients = \"\"\n",
    "    context = \"\"\n",
    "    \n",
    "    # Handle the format\n",
    "    if \"Ingredients:\" in raw_input:\n",
    "        parts = raw_input.split(\"Context:\")\n",
    "        ingredients = parts[0].replace(\"Ingredients:\", \"\").strip()\n",
    "        if ingredients.endswith(('.', ',')):\n",
    "            ingredients = ingredients[:-1]\n",
    "            \n",
    "        if len(parts) > 1:\n",
    "            context = parts[1].strip()\n",
    "\n",
    "    # Build New Instruction\n",
    "    # Limiting to first 4 ingredients so the user prompt sounds natural\n",
    "    ing_list = [x.strip() for x in ingredients.split(',')]\n",
    "    main_ingredients = \", \".join(ing_list[:4]) \n",
    "    \n",
    "    if context:\n",
    "        template = random.choice(CONTEXT_PROMPTS)\n",
    "        new_instruction = template.format(context=context.lower(), ingredients=main_ingredients)\n",
    "    else:\n",
    "        template = random.choice(INGREDIENT_PROMPTS)\n",
    "        new_instruction = template.format(ingredients=main_ingredients)\n",
    "\n",
    "    # Build New Output\n",
    "    intro = random.choice(CHEF_INTROS)\n",
    "    clean_recipe = raw_output.replace(\"</s>\", \"\").strip()\n",
    "    \n",
    "    # Combining Intro + Recipe\n",
    "    new_output = f\"{intro}{clean_recipe}\"\n",
    "    \n",
    "    # Return in the format of input output\n",
    "    return pd.Series([new_instruction, \"\", new_output])\n",
    "\n",
    "print(\"Harmonizing recipe formats (This may take a moment)...\")\n",
    "# Apply transformation to the Training Subset\n",
    "train_recipes_df[['instruction', 'input', 'output']] = train_recipes_df.apply(harmonize_row, axis=1)\n",
    "print(\"‚úÖ Recipes Harmonized to Chef Persona\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920b45bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading new Chef Persona data...\n",
      "‚úÖ Loaded 4720 Chef Persona examples\n",
      "üöÄ Final Dataset Size: 24720 rows\n",
      "üíæ Saved to data/training/hybrid_train.jsonl\n",
      "Ready for Fine-Tuning!\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading new Chef Persona data...\")\n",
    "new_data_files = glob.glob(NEW_CHEF_DATA_FOLDER)\n",
    "new_data_list = []\n",
    "\n",
    "for file in new_data_files:\n",
    "    try:\n",
    "        with open(file, 'r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                if line.strip():\n",
    "                    new_data_list.append(json.loads(line))\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {file}: {e}\")\n",
    "\n",
    "chef_persona_df = pd.DataFrame(new_data_list)\n",
    "print(f\"‚úÖ Loaded {len(chef_persona_df)} Chef Persona examples\")\n",
    "\n",
    "# Merging\n",
    "# Combine 20k Harmonized Recipes + 5k Chef Persona Examples\n",
    "final_df = pd.concat([train_recipes_df, chef_persona_df], ignore_index=True)\n",
    "\n",
    "# Shuffling\n",
    "final_df = shuffle(final_df, random_state=42).reset_index(drop=True)\n",
    "\n",
    "print(f\"üöÄ Final Dataset Size: {len(final_df)} rows\")\n",
    "\n",
    "# Save\n",
    "os.makedirs(os.path.dirname(TRAIN_OUTPUT_PATH), exist_ok=True)\n",
    "final_df.to_json(TRAIN_OUTPUT_PATH, orient='records', lines=True)\n",
    "\n",
    "print(f\"üíæ Saved to {TRAIN_OUTPUT_PATH}\")\n",
    "print(\"Ready for Fine-Tuning!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
